{"cells":[{"cell_type":"markdown","metadata":{"id":"pSS4ThYGXrgB"},"source":["##Load, Explore and Summerize"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4103,"status":"ok","timestamp":1728307198652,"user":{"displayName":"Athoye Mahmud (অথৈ)","userId":"05993942951772728166"},"user_tz":-360},"id":"zuzKHILZWFbE","outputId":"f9194d1b-7ea8-4ce4-e609-b18050b4073b"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 116892 entries, 0 to 116891\n","Data columns (total 24 columns):\n"," #   Column                             Non-Null Count   Dtype  \n","---  ------                             --------------   -----  \n"," 0   Id                                 116892 non-null  int64  \n"," 1   satisfaction                       116892 non-null  object \n"," 2   Gender                             116892 non-null  object \n"," 3   Customer Type                      116892 non-null  object \n"," 4   Age                                116892 non-null  int64  \n"," 5   Type of Travel                     116892 non-null  object \n"," 6   Class                              116892 non-null  object \n"," 7   Flight Distance                    116892 non-null  int64  \n"," 8   Seat comfort                       116892 non-null  int64  \n"," 9   Departure/Arrival time convenient  116892 non-null  int64  \n"," 10  Food and drink                     116892 non-null  int64  \n"," 11  Gate location                      116892 non-null  int64  \n"," 12  Inflight wifi service              116892 non-null  int64  \n"," 13  Inflight entertainment             116892 non-null  int64  \n"," 14  Online support                     116892 non-null  int64  \n"," 15  Ease of Online booking             116892 non-null  int64  \n"," 16  On-board service                   116892 non-null  int64  \n"," 17  Leg room service                   116892 non-null  int64  \n"," 18  Baggage handling                   116892 non-null  int64  \n"," 19  Checkin service                    116892 non-null  int64  \n"," 20  Cleanliness                        116892 non-null  int64  \n"," 21  Online boarding                    116892 non-null  int64  \n"," 22  Departure Delay in Minutes         116892 non-null  int64  \n"," 23  Arrival Delay in Minutes           116541 non-null  float64\n","dtypes: float64(1), int64(18), object(5)\n","memory usage: 21.4+ MB\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 12949 entries, 0 to 12948\n","Data columns (total 23 columns):\n"," #   Column                             Non-Null Count  Dtype \n","---  ------                             --------------  ----- \n"," 0   Id                                 12949 non-null  int64 \n"," 1   Gender                             12949 non-null  object\n"," 2   Customer Type                      12949 non-null  object\n"," 3   Age                                12949 non-null  int64 \n"," 4   Type of Travel                     12949 non-null  object\n"," 5   Class                              12949 non-null  object\n"," 6   Flight Distance                    12949 non-null  int64 \n"," 7   Seat comfort                       12949 non-null  int64 \n"," 8   Departure/Arrival time convenient  12949 non-null  int64 \n"," 9   Food and drink                     12949 non-null  int64 \n"," 10  Gate location                      12949 non-null  int64 \n"," 11  Inflight wifi service              12949 non-null  int64 \n"," 12  Inflight entertainment             12949 non-null  int64 \n"," 13  Online support                     12949 non-null  int64 \n"," 14  Ease of Online booking             12949 non-null  int64 \n"," 15  On-board service                   12949 non-null  int64 \n"," 16  Leg room service                   12949 non-null  int64 \n"," 17  Baggage handling                   12949 non-null  int64 \n"," 18  Checkin service                    12949 non-null  int64 \n"," 19  Cleanliness                        12949 non-null  int64 \n"," 20  Online boarding                    12949 non-null  int64 \n"," 21  Departure Delay in Minutes         12949 non-null  int64 \n"," 22  Arrival Delay in Minutes           12949 non-null  int64 \n","dtypes: int64(19), object(4)\n","memory usage: 2.3+ MB\n"]},{"output_type":"execute_result","data":{"text/plain":["(None,\n","        Id  satisfaction  Gender   Customer Type  Age   Type of Travel  \\\n"," 0   86347     satisfied    Male  Loyal Customer   50  Business travel   \n"," 1  115822     satisfied    Male  Loyal Customer   51  Business travel   \n"," 2   16351  dissatisfied    Male  Loyal Customer   14  Personal Travel   \n"," 3  107284     satisfied  Female  Loyal Customer   52  Business travel   \n"," 4    5788  dissatisfied  Female  Loyal Customer   26  Personal Travel   \n"," \n","       Class  Flight Distance  Seat comfort  Departure/Arrival time convenient  \\\n"," 0  Business             1548             5                                  5   \n"," 1  Business             4020             5                                  5   \n"," 2       Eco             2328             2                                  5   \n"," 3  Business             3761             2                                  2   \n"," 4       Eco             3348             1                                  5   \n"," \n","    ...  Online support  Ease of Online booking  On-board service  \\\n"," 0  ...               5                       3                 3   \n"," 1  ...               4                       5                 5   \n"," 2  ...               1                       1                 5   \n"," 3  ...               5                       4                 4   \n"," 4  ...               5                       5                 3   \n"," \n","    Leg room service  Baggage handling  Checkin service  Cleanliness  \\\n"," 0                 3                 3                5            3   \n"," 1                 5                 5                5            5   \n"," 2                 3                 3                4            4   \n"," 3                 4                 4                4            4   \n"," 4                 4                 3                5            1   \n"," \n","    Online boarding  Departure Delay in Minutes  Arrival Delay in Minutes  \n"," 0                4                           0                       0.0  \n"," 1                5                          53                      51.0  \n"," 2                1                           0                       4.0  \n"," 3                5                          61                      55.0  \n"," 4                5                         196                     169.0  \n"," \n"," [5 rows x 24 columns],\n"," None,\n","        Id  Gender      Customer Type  Age   Type of Travel     Class  \\\n"," 0   46587  Female  disloyal Customer   22  Business travel       Eco   \n"," 1  124920    Male     Loyal Customer   25  Business travel  Business   \n"," 2   18490  Female     Loyal Customer   21  Personal Travel       Eco   \n"," 3   78644  Female     Loyal Customer   34  Business travel  Business   \n"," 4   92713    Male     Loyal Customer   39  Business travel  Business   \n"," \n","    Flight Distance  Seat comfort  Departure/Arrival time convenient  \\\n"," 0             2354             2                                  2   \n"," 1             2855             2                                  2   \n"," 2             1250             4                                  4   \n"," 3               95             1                                  2   \n"," 4             3276             5                                  2   \n"," \n","    Food and drink  ...  Online support  Ease of Online booking  \\\n"," 0               2  ...               2                       2   \n"," 1               2  ...               5                       5   \n"," 2               4  ...               4                       4   \n"," 3               2  ...               3                       3   \n"," 4               5  ...               5                       4   \n"," \n","    On-board service  Leg room service  Baggage handling  Checkin service  \\\n"," 0                 1                 4                 3                4   \n"," 1                 3                 4                 1                1   \n"," 2                 4                 4                 4                4   \n"," 3                 3                 3                 1                3   \n"," 4                 4                 4                 4                4   \n"," \n","    Cleanliness  Online boarding  Departure Delay in Minutes  \\\n"," 0            3                2                          13   \n"," 1            5                5                           0   \n"," 2            4                5                           0   \n"," 3            3                3                          12   \n"," 4            4                3                           0   \n"," \n","    Arrival Delay in Minutes  \n"," 0                        23  \n"," 1                         5  \n"," 2                         0  \n"," 3                         9  \n"," 4                         0  \n"," \n"," [5 rows x 23 columns],\n","        ID  satisfaction\n"," 0   46587  dissatisfied\n"," 1  124920     satisfied\n"," 2   18490     satisfied\n"," 3   78644  dissatisfied\n"," 4   92713     satisfied)"]},"metadata":{},"execution_count":2}],"source":["import pandas as pd\n","import numpy as np\n","\n","# Load the train, test, and sample submission datasets\n","train_path = '/content/drive/MyDrive/Code/DS_1101/Fly High With FDS/train.csv'\n","test_path = '/content/drive/MyDrive/Code/DS_1101/Fly High With FDS/test.csv'\n","submission_path = '/content/drive/MyDrive/Code/DS_1101/Fly High With FDS/sample_submission.csv'\n","\n","train_df = pd.read_csv(train_path)\n","test_df = pd.read_csv(test_path)\n","sample_submission_df = pd.read_csv(submission_path)\n","\n","# Display basic information about the datasets\n","train_info = train_df.info()\n","test_info = test_df.info()\n","\n","# Display first few rows of the train and test data\n","train_head = train_df.head()\n","test_head = test_df.head()\n","\n","# Display the first few rows of the sample submission file\n","sample_submission_head = sample_submission_df.head()\n","\n","train_info, train_head, test_info, test_head, sample_submission_head"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":458,"status":"ok","timestamp":1728307205115,"user":{"displayName":"Athoye Mahmud (অথৈ)","userId":"05993942951772728166"},"user_tz":-360},"id":"gpJ2QfcgFeH9","outputId":"c4ada530-ec4d-4be8-910a-2cec6ce55b87"},"outputs":[{"output_type":"stream","name":"stdout","text":["['Id', 'satisfaction', 'Gender', 'Customer Type', 'Age', 'Type of Travel', 'Class', 'Flight Distance', 'Seat comfort', 'Departure/Arrival time convenient', 'Food and drink', 'Gate location', 'Inflight wifi service', 'Inflight entertainment', 'Online support', 'Ease of Online booking', 'On-board service', 'Leg room service', 'Baggage handling', 'Checkin service', 'Cleanliness', 'Online boarding', 'Departure Delay in Minutes', 'Arrival Delay in Minutes']\n"]}],"source":["print(train_df.columns.tolist())"]},{"cell_type":"markdown","metadata":{"id":"X6wimx0ZXlie"},"source":["##Preprocessing and Modeling"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":558,"status":"ok","timestamp":1728168751313,"user":{"displayName":"Athoye Mahmud (অথৈ)","userId":"05993942951772728166"},"user_tz":-360},"id":"EiI_qv1dXRQd","outputId":"36d11309-1899-446f-c01f-ded30c858a6d"},"outputs":[{"data":{"text/plain":["(       Gender  Customer Type  Age  Type of Travel  Class  Flight Distance  \\\n"," 94821       1              1   31               0      0             2702   \n"," 83138       1              0   49               0      0             2301   \n"," 7527        1              0   24               1      1             1215   \n"," 15564       0              0   53               0      1              238   \n"," 42362       1              0   26               0      0             3123   \n"," \n","        Seat comfort  Departure/Arrival time convenient  Food and drink  \\\n"," 94821             2                                  2               2   \n"," 83138             2                                  2               2   \n"," 7527              4                                  5               4   \n"," 15564             5                                  2               2   \n"," 42362             4                                  4               2   \n"," \n","        Gate location  ...  Online support  Ease of Online booking  \\\n"," 94821              3  ...               1                       2   \n"," 83138              2  ...               5                       4   \n"," 7527               2  ...               1                       1   \n"," 15564              2  ...               2                       5   \n"," 42362              4  ...               5                       5   \n"," \n","        On-board service  Leg room service  Baggage handling  Checkin service  \\\n"," 94821                 4                 1                 3                3   \n"," 83138                 4                 4                 4                5   \n"," 7527                  5                 2                 4                4   \n"," 15564                 5                 5                 5                2   \n"," 42362                 3                 4                 4                5   \n"," \n","        Cleanliness  Online boarding  Departure Delay in Minutes  \\\n"," 94821            2                2                          34   \n"," 83138            4                5                           0   \n"," 7527             4                1                           0   \n"," 15564            5                4                           0   \n"," 42362            4                5                          52   \n"," \n","        Arrival Delay in Minutes  \n"," 94821                      24.0  \n"," 83138                       0.0  \n"," 7527                        0.0  \n"," 15564                       1.0  \n"," 42362                      32.0  \n"," \n"," [5 rows x 22 columns],\n"," 94821    0\n"," 83138    1\n"," 7527     1\n"," 15564    1\n"," 42362    1\n"," Name: satisfaction, dtype: int64)"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.impute import SimpleImputer\n","\n","# Dropping the ID column (not useful for modeling) from both train and test\n","train_df_clean = train_df.drop(columns=['Id'])\n","test_df_clean = test_df.drop(columns=['Id'])\n","\n","# Impute missing values in the 'Arrival Delay in Minutes' with median\n","imputer = SimpleImputer(strategy='median')\n","train_df_clean['Arrival Delay in Minutes'] = imputer.fit_transform(train_df_clean[['Arrival Delay in Minutes']])\n","test_df_clean['Arrival Delay in Minutes'] = imputer.transform(test_df_clean[['Arrival Delay in Minutes']])\n","\n","# Encode categorical variables using LabelEncoder\n","categorical_cols = ['Gender', 'Customer Type', 'Type of Travel', 'Class']\n","\n","label_encoders = {}\n","for col in categorical_cols:\n","    le = LabelEncoder()\n","    train_df_clean[col] = le.fit_transform(train_df_clean[col])\n","    test_df_clean[col] = le.transform(test_df_clean[col])\n","    label_encoders[col] = le\n","\n","# Encode the target variable 'satisfaction'\n","train_df_clean['satisfaction'] = train_df_clean['satisfaction'].map({'satisfied': 1, 'dissatisfied': 0})\n","\n","X = train_df_clean.drop(columns=['satisfaction'])\n","y = train_df_clean['satisfaction']\n","\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","\n","X_train.head(), y_train.head()"]},{"cell_type":"markdown","metadata":{"id":"UJIW6n_5X6KO"},"source":["##Basic Random Forest Classifier Model Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23894,"status":"ok","timestamp":1728130121451,"user":{"displayName":"Athoye Mahmud (অথৈ)","userId":"05993942951772728166"},"user_tz":-360},"id":"ZUGbqHCtX5Fc","outputId":"382251a7-1d33-48d6-aa72-cc83fbd4f5f8"},"outputs":[{"data":{"text/plain":["(0.9586380940159973,\n"," '              precision    recall  f1-score   support\\n\\n           0       0.94      0.97      0.95     10585\\n           1       0.97      0.95      0.96     12794\\n\\n    accuracy                           0.96     23379\\n   macro avg       0.96      0.96      0.96     23379\\nweighted avg       0.96      0.96      0.96     23379\\n')"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","\n","rf_model.fit(X_train, y_train)\n","\n","y_val_pred = rf_model.predict(X_val)\n","\n","val_accuracy = accuracy_score(y_val, y_val_pred)\n","val_classification_report = classification_report(y_val, y_val_pred)\n","\n","val_accuracy, val_classification_report"]},{"cell_type":"markdown","metadata":{"id":"gzGxZ6NWyPlz"},"source":["First attempt with Basic RFC 5/10/24; score - 0.97 ~ 0.988033"]},{"cell_type":"markdown","metadata":{"id":"3Z2mm2TSYuN2"},"source":["##Prediction and Submission File Prep"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":979,"status":"ok","timestamp":1728137183867,"user":{"displayName":"Athoye Mahmud (অথৈ)","userId":"05993942951772728166"},"user_tz":-360},"id":"Qnr1RFKvYzjO","outputId":"24e113d4-f30e-40c1-fd24-678ac1aee56c"},"outputs":[{"data":{"text/plain":["(       ID  satisfaction\n"," 0   46587  dissatisfied\n"," 1  124920     satisfied\n"," 2   18490     satisfied\n"," 3   78644  dissatisfied\n"," 4   92713     satisfied,\n"," '/content/drive/MyDrive/Code/DS_1101/Fly High With FDS/submission.csv')"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["test_predictions = rf_model.predict(test_df_clean)\n","\n","submission_df = pd.DataFrame({\n","    'ID': test_df['Id'],\n","    'satisfaction': test_predictions\n","})\n","\n","submission_df['satisfaction'] = submission_df['satisfaction'].map({1: 'satisfied', 0: 'dissatisfied'})\n","\n","submission_file_path = '/content/drive/MyDrive/Code/DS_1101/Fly High With FDS/submission.csv'\n","submission_df.to_csv(submission_file_path, index=False)\n","\n","submission_df.head(), submission_file_path"]},{"cell_type":"markdown","source":["##Tune-maxxing the Random Forest"],"metadata":{"id":"NGpQLDF8ubEP"}},{"cell_type":"code","source":["!pip install category_encoders\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from category_encoders import TargetEncoder\n","\n","# Define the preprocess_data function\n","def preprocess_data(train_df, test_df):\n","    # Separate features and target variable\n","    X = train_df.drop(['satisfaction', 'Id'], axis=1)\n","    y = train_df['satisfaction'].map({'satisfied': 1, 'neutral or dissatisfied': 0})\n","    X_test = test_df.drop('Id', axis=1)\n","\n","    # Identify numerical and categorical features\n","    numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n","    categorical_features = X.select_dtypes(include=['object']).columns\n","\n","    # Create transformers for numerical and categorical features\n","    numerical_transformer = Pipeline(steps=[\n","        ('imputer', SimpleImputer(strategy='median')),\n","        ('scaler', StandardScaler())\n","    ])\n","\n","    categorical_transformer = Pipeline(steps=[\n","        ('imputer', SimpleImputer(strategy='most_frequent')),\n","        ('target_encoder', TargetEncoder())  # Using TargetEncoder\n","    ])\n","\n","    # Combine transformers using ColumnTransformer\n","    preprocessor = ColumnTransformer(\n","        transformers=[\n","            ('num', numerical_transformer, numerical_features),\n","            ('cat', categorical_transformer, categorical_features)\n","        ])\n","\n","    # Handle missing values in the target variable (y) before fitting\n","    y = y.fillna(y.mode()[0]) # Fill missing values with the mode\n","\n","    # Fit and transform the training data\n","    X = preprocessor.fit_transform(X, y)\n","\n","    # Transform the test data\n","    X_test = preprocessor.transform(X_test)\n","\n","    return X, X_test, y\n","\n","# Load and preprocess\n","train_df = pd.read_csv('train.csv')\n","test_df = pd.read_csv('test.csv')\n","X, X_test, y = preprocess_data(train_df, test_df)  # Use the preprocessed data\n","\n","# Split data\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","\n","# Hyperparameter Tuning with RandomizedSearchCV (More efficient than GridSearchCV)\n","param_dist = {\n","    'n_estimators': [100, 200, 300, 500],  # Explore a range\n","    'max_depth': [None, 10, 20, 30],         # Include None for full depth\n","    'min_samples_split': [2, 5, 10],        # Experiment with splitting criteria\n","    'min_samples_leaf': [1, 2, 4],          # Control leaf size\n","    'max_features': ['sqrt', 'log2', None], # Or a float between 0 and 1\n","    'bootstrap': [True, False],            # Bagging (with replacement) or Pasting\n","    'class_weight': [None, 'balanced', 'balanced_subsample'] # Adjust for class imbalance (if any)\n","}\n","\n","\n","\n","rf = RandomForestClassifier(random_state=42)\n","random_search = RandomizedSearchCV(\n","    rf, param_distributions=param_dist, n_iter=50,\n","    scoring='accuracy', cv=5, n_jobs=-1, verbose=2, random_state=42\n",")\n","\n","random_search.fit(X_train, y_train)\n","\n","\n","\n","# Evaluate and Print Best Parameters\n","print(\"Best Hyperparameters:\", random_search.best_params_)\n","best_rf = random_search.best_estimator_\n","\n","\n","y_pred = best_rf.predict(X_val)\n","accuracy = accuracy_score(y_val, y_pred)\n","print(f\"Validation Accuracy: {accuracy}\")\n","print(classification_report(y_val, y_pred))\n","\n","\n","# Train best model on full training data (if needed for final prediction on the test set). If not needed, skip and use random search for test predictions.\n","\n","best_rf.fit(X, y) # Fit on the full training set\n","\n","\n","# Make predictions on the test set\n","test_predictions = best_rf.predict(X_test)\n","\n","# Prepare submission\n","submission_df = pd.DataFrame({\n","    'ID': test_df['Id'],\n","    'satisfaction': test_predictions\n","})\n","submission_df['satisfaction'] = submission_df['satisfaction'].map({1: 'satisfied', 0: 'dissatisfied'})\n","submission_df.to_csv('random_forest_tuned_submission.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TmSWawliueUA","executionInfo":{"status":"ok","timestamp":1728318179799,"user_tz":-360,"elapsed":34843,"user":{"displayName":"Athoye Mahmud (অথৈ)","userId":"05993942951772728166"}},"outputId":"54698f70-c377-459a-9ba8-8a3331c05b67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: category_encoders in /usr/local/lib/python3.10/dist-packages (2.6.4)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.26.4)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.5.2)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.13.1)\n","Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.14.3)\n","Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (2.2.2)\n","Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.5.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2024.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.5.0)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.9.0->category_encoders) (24.1)\n","Fitting 5 folds for each of 50 candidates, totalling 250 fits\n","Best Hyperparameters: {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 10, 'class_weight': 'balanced_subsample', 'bootstrap': False}\n","Validation Accuracy: 1.0\n","              precision    recall  f1-score   support\n","\n","         1.0       1.00      1.00      1.00     23379\n","\n","    accuracy                           1.00     23379\n","   macro avg       1.00      1.00      1.00     23379\n","weighted avg       1.00      1.00      1.00     23379\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"wdV0-jIksHaT"},"source":["#Before implementing more complex models-"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H7IOvZ2RsPQI"},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"markdown","metadata":{"id":"bBo6-eZi4Q2T"},"source":["## Hyperparameter Tuning (Random Forest)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a3_K-BVR4TUt"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import GridSearchCV\n","\n","# Define the parameter grid for Random Forest\n","param_grid = {\n","    'n_estimators': [100, 200, 300],\n","    'max_depth': [10, 20, 30, None],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4],\n","    'bootstrap': [True, False]\n","}\n","\n","# Initialize the RandomForestClassifier\n","rf = RandomForestClassifier(random_state=42)\n","\n","# Use GridSearchCV to search for the best hyperparameters\n","grid_search_rf = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n","\n","# Fit the grid search\n","grid_search_rf.fit(X_train_scaled, y_train)\n","\n","# Best parameters and best score\n","print(\"Best Parameters: \", grid_search_rf.best_params_)\n","print(\"Best Cross-Validation Score: \", grid_search_rf.best_score_)\n","\n","# Train on full training data with best params\n","best_rf_model = grid_search_rf.best_estimator_\n","best_rf_model.fit(X_train_scaled, y_train)\n","\n","# Predict on the test set\n","test_predictions_rf = best_rf_model.predict(test_scaled)\n","\n","# Submission\n","submission_rf = pd.DataFrame({\n","    'ID': test_df['Id'],\n","    'satisfaction': test_predictions_rf\n","})\n","submission_rf['satisfaction'] = submission_rf['satisfaction'].map({1: 'satisfied', 0: 'dissatisfied'})\n","submission_rf.to_csv('submission_rf_optimized.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"39uzmMkPJb8u"},"source":["##XGBoost Implementation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"executionInfo":{"elapsed":979685,"status":"ok","timestamp":1728140910985,"user":{"displayName":"Athoye Mahmud (অথৈ)","userId":"05993942951772728166"},"user_tz":-360},"id":"UKsTqz2dJJbw","outputId":"14850243-69fe-4c93-cd18-abd953287205"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n","Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n","Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [15:08:25] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"name":"stdout","output_type":"stream","text":["Best hyperparameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 300, 'subsample': 1}\n","XGBoost Validation Accuracy: 0.9609478591898712\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"submission_df\",\n  \"rows\": 12949,\n  \"fields\": [\n    {\n      \"column\": \"Id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37441,\n        \"min\": 35,\n        \"max\": 129863,\n        \"num_unique_values\": 12949,\n        \"samples\": [\n          71878,\n          77312,\n          124340\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"satisfaction\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"satisfied\",\n          \"dissatisfied\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"submission_df"},"text/html":["\n","  <div id=\"df-26b8ea7c-a3c4-432c-9485-22c8207b567f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>satisfaction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>46587</td>\n","      <td>dissatisfied</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>124920</td>\n","      <td>satisfied</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>18490</td>\n","      <td>satisfied</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>78644</td>\n","      <td>dissatisfied</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>92713</td>\n","      <td>satisfied</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26b8ea7c-a3c4-432c-9485-22c8207b567f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-26b8ea7c-a3c4-432c-9485-22c8207b567f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-26b8ea7c-a3c4-432c-9485-22c8207b567f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-9bacd1ea-b06b-4a8c-a11e-206573c8a6bb\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9bacd1ea-b06b-4a8c-a11e-206573c8a6bb')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-9bacd1ea-b06b-4a8c-a11e-206573c8a6bb button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["       Id  satisfaction\n","0   46587  dissatisfied\n","1  124920     satisfied\n","2   18490     satisfied\n","3   78644  dissatisfied\n","4   92713     satisfied"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["!pip install xgboost\n","import xgboost as xgb\n","from sklearn.model_selection import GridSearchCV\n","\n","# Initialize the XGBoost classifier\n","xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n","\n","# Set a parameter grid for hyperparameter tuning\n","param_grid = {\n","    'n_estimators': [100, 300, 500],\n","    'max_depth': [3, 6, 9],\n","    'learning_rate': [0.01, 0.1, 0.3],\n","    'subsample': [0.8, 1],\n","    'colsample_bytree': [0.8, 1]\n","}\n","\n","# Perform grid search\n","grid_search = GridSearchCV(xgb_model, param_grid, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n","grid_search.fit(X_train, y_train)\n","\n","# Check the best parameters from the grid search\n","best_params = grid_search.best_params_\n","print(f\"Best hyperparameters: {best_params}\")\n","\n","# Train the model with the best parameters\n","xgb_best = grid_search.best_estimator_\n","\n","# Evaluate on the validation set\n","y_val_pred_xgb = xgb_best.predict(X_val)\n","xgb_accuracy = accuracy_score(y_val, y_val_pred_xgb)\n","print(f\"XGBoost Validation Accuracy: {xgb_accuracy}\")\n","\n","test_predictions_xgb = xgb_best.predict(test_df_clean)\n","\n","# Prepare submission file\n","submission_df = pd.DataFrame({\n","    'ID': test_df['Id'],\n","    'satisfaction': test_predictions_xgb\n","})\n","\n","# Convert satisfaction back to original labels\n","submission_df['satisfaction'] = submission_df['satisfaction'].map({1: 'satisfied', 0: 'dissatisfied'})\n","\n","# Save submission\n","submission_df.to_csv('submission_xgboost.csv', index=False)\n","\n","submission_df.head()"]},{"cell_type":"markdown","metadata":{"id":"T22iBmcYOarQ"},"source":["##Binary Decision Trees"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33306,"status":"ok","timestamp":1728256698046,"user":{"displayName":"Athoye Mahmud (অথৈ)","userId":"05993942951772728166"},"user_tz":-360},"id":"VHWc4pzyOiDW","outputId":"4e73774a-9184-4fb1-da60-e0c0687b360f"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n","  _data = np.array(data, dtype=dtype, copy=copy,\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Decision Tree Validation Accuracy: 0.910004705077206\n","Decision Tree submission file saved as 'submission_decision_tree.csv'\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n","  warnings.warn(\n"]}],"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import GridSearchCV\n","\n","# Initialize Decision Tree Classifier\n","dt_model = DecisionTreeClassifier(random_state=42)\n","\n","# Set parameter grid for hyperparameter tuning\n","param_grid_dt = {\n","    'max_depth': [3, 6, 9],\n","    'min_samples_split': [10, 20, 50],\n","    'min_samples_leaf': [5, 10, 20]\n","}\n","\n","# Perform Grid Search\n","grid_search_dt = GridSearchCV(dt_model, param_grid_dt, cv=3, scoring='accuracy', n_jobs=-1)\n","grid_search_dt.fit(X_train, y_train)\n","\n","# Get best estimator and evaluate on validation set\n","dt_best = grid_search_dt.best_estimator_\n","y_val_pred_dt = dt_best.predict(X_val)\n","dt_accuracy = accuracy_score(y_val, y_val_pred_dt)\n","print(f\"Decision Tree Validation Accuracy: {dt_accuracy}\")\n","\n","# Make predictions on the test set\n","test_predictions_dt = dt_best.predict(test_df_clean)\n","\n","# Prepare the submission DataFrame\n","submission_dt = pd.DataFrame({\n","    'ID': test_df['Id'],\n","    'satisfaction': test_predictions_dt\n","})\n","\n","# Convert numeric labels back to original text ('satisfied', 'dissatisfied')\n","submission_dt['satisfaction'] = submission_dt['satisfaction'].map({1: 'satisfied', 0: 'dissatisfied'})\n","\n","# Save submission to CSV\n","submission_dt.to_csv('submission_decision_tree.csv', index=False)\n","print(\"Decision Tree submission file saved as 'submission_decision_tree.csv'\")"]},{"cell_type":"markdown","metadata":{"id":"7-qp67UhTXbO"},"source":["##Logistic Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1449,"status":"ok","timestamp":1728165739252,"user":{"displayName":"Athoye Mahmud (অথৈ)","userId":"05993942951772728166"},"user_tz":-360},"id":"a6UABOUETb8S","outputId":"74d13025-c545-424a-b862-81017a1c9d1d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Logistic Regression Validation Accuracy: 0.8364344069464049\n","Logistic Regression submission file saved as 'submission_logistic_regression.csv'\n"]}],"source":["from sklearn.linear_model import LogisticRegression\n","\n","# Scale the data\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_val_scaled = scaler.transform(X_val)\n","test_scaled = scaler.transform(test_df_clean)  # Ensure the test set is scaled as well\n","\n","# Initialize Logistic Regression with L2 regularization\n","logreg_model = LogisticRegression(solver='liblinear', random_state=42)\n","\n","# Fit the model\n","logreg_model.fit(X_train_scaled, y_train)\n","\n","# Evaluate on validation set\n","y_val_pred_logreg = logreg_model.predict(X_val_scaled)\n","logreg_accuracy = accuracy_score(y_val, y_val_pred_logreg)\n","print(f\"Logistic Regression Validation Accuracy: {logreg_accuracy}\")\n","\n","# Make predictions on the test set\n","test_predictions_logreg = logreg_model.predict(test_scaled)\n","\n","# Prepare the submission DataFrame\n","submission_logreg = pd.DataFrame({\n","    'ID': test_df['Id'],\n","    'satisfaction': test_predictions_logreg\n","})\n","\n","# Convert numeric labels back to original text ('satisfied', 'dissatisfied')\n","submission_logreg['satisfaction'] = submission_logreg['satisfaction'].map({1: 'satisfied', 0: 'dissatisfied'})\n","\n","# Save submission to CSV\n","submission_logreg.to_csv('submission_logistic_regression.csv', index=False)\n","print(\"Logistic Regression submission file saved as 'submission_logistic_regression.csv'\")"]},{"cell_type":"markdown","metadata":{"id":"Z2H4oel2ViHd"},"source":["##Support Vector Machines (SVMs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":781307,"status":"ok","timestamp":1728166578583,"user":{"displayName":"Athoye Mahmud (অথৈ)","userId":"05993942951772728166"},"user_tz":-360},"id":"5o0TTRQgVsP4","outputId":"f4c3792c-b8d2-40ee-966f-70bd26156ce3"},"outputs":[{"name":"stdout","output_type":"stream","text":["SVM Validation Accuracy: 0.8404123358569656\n","SVM submission file saved as 'submission_svm.csv'\n"]}],"source":["from sklearn.svm import SVC\n","from sklearn.preprocessing import StandardScaler\n","\n","# Scale the data\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_val_scaled = scaler.transform(X_val)\n","\n","# Initialize SVM with linear kernel for speed\n","svm_model = SVC(kernel='linear', random_state=42)\n","\n","# Fit and evaluate\n","svm_model.fit(X_train_scaled, y_train)\n","y_val_pred_svm = svm_model.predict(X_val_scaled)\n","\n","# Evaluate performance\n","svm_accuracy = accuracy_score(y_val, y_val_pred_svm)\n","print(f\"SVM Validation Accuracy: {svm_accuracy}\")\n","\n","# Scale the test set\n","test_scaled = scaler.transform(test_df_clean)\n","\n","# Make predictions on the test set\n","test_predictions_svm = svm_model.predict(test_scaled)\n","\n","# Prepare the submission DataFrame\n","submission_svm = pd.DataFrame({\n","    'ID': test_df['Id'],\n","    'satisfaction': test_predictions_svm\n","})\n","\n","# Convert numeric labels back to original text ('satisfied', 'dissatisfied')\n","submission_svm['satisfaction'] = submission_svm['satisfaction'].map({1: 'satisfied', 0: 'dissatisfied'})\n","\n","# Save submission to CSV\n","submission_svm.to_csv('submission_svm.csv', index=False)\n","print(\"SVM submission file saved as 'submission_svm.csv'\")"]},{"cell_type":"markdown","metadata":{"id":"Zy5vxPC4X3Kx"},"source":["##Ensemble Methods; Voting Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14249,"status":"ok","timestamp":1728167620146,"user":{"displayName":"Athoye Mahmud (অথৈ)","userId":"05993942951772728166"},"user_tz":-360},"id":"k0ksf_svX_lP","outputId":"f9015ea3-7b0a-4716-a567-fb3c848e207a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Voting Classifier Validation Accuracy: 0.9304076307797596\n","Voting Classifier submission file saved as 'submission_voting.csv'\n"]}],"source":["from sklearn.ensemble import VotingClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# Define individual models\n","logreg = LogisticRegression(solver='liblinear', random_state=42)\n","dt = DecisionTreeClassifier(max_depth=6, random_state=42)\n","rf = RandomForestClassifier(n_estimators=100, random_state=42)\n","\n","# Create Voting Classifier (hard voting)\n","voting_clf = VotingClassifier(estimators=[('lr', logreg), ('dt', dt), ('rf', rf)], voting='hard')\n","\n","# Fit the model\n","voting_clf.fit(X_train, y_train)\n","\n","# Evaluate on validation set\n","y_val_pred_voting = voting_clf.predict(X_val)\n","voting_accuracy = accuracy_score(y_val, y_val_pred_voting)\n","print(f\"Voting Classifier Validation Accuracy: {voting_accuracy}\")\n","\n","# Make predictions on the test set\n","test_predictions_voting = voting_clf.predict(test_df_clean)\n","\n","# Prepare the submission\n","submission_voting = pd.DataFrame({\n","    'ID': test_df['Id'],\n","    'satisfaction': test_predictions_voting\n","})\n","\n","submission_voting['satisfaction'] = submission_voting['satisfaction'].map({1: 'satisfied', 0: 'dissatisfied'})\n","submission_voting.to_csv('submission_voting.csv', index=False)\n","print(\"Voting Classifier submission file saved as 'submission_voting.csv'\")"]},{"cell_type":"markdown","metadata":{"id":"z9naf3JK473O"},"source":["##Ensemble Stacking"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":324012,"status":"ok","timestamp":1728247833502,"user":{"displayName":"Athoye Mahmud (অথৈ)","userId":"05993942951772728166"},"user_tz":-360},"id":"LpZy8i_749lZ","outputId":"eb8543e3-9dbc-4847-fd64-9e3aea66c51f"},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 51179, number of negative: 42334\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010372 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1208\n","[LightGBM] [Info] Number of data points in the train set: 93513, number of used features: 28\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547293 -> initscore=0.189739\n","[LightGBM] [Info] Start training from score 0.189739\n","[LightGBM] [Info] Number of positive: 40943, number of negative: 33867\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013784 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1208\n","[LightGBM] [Info] Number of data points in the train set: 74810, number of used features: 28\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547293 -> initscore=0.189740\n","[LightGBM] [Info] Start training from score 0.189740\n","[LightGBM] [Info] Number of positive: 40943, number of negative: 33867\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013042 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1208\n","[LightGBM] [Info] Number of data points in the train set: 74810, number of used features: 28\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547293 -> initscore=0.189740\n","[LightGBM] [Info] Start training from score 0.189740\n","[LightGBM] [Info] Number of positive: 40943, number of negative: 33867\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021239 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1208\n","[LightGBM] [Info] Number of data points in the train set: 74810, number of used features: 28\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547293 -> initscore=0.189740\n","[LightGBM] [Info] Start training from score 0.189740\n","[LightGBM] [Info] Number of positive: 40943, number of negative: 33868\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028661 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1206\n","[LightGBM] [Info] Number of data points in the train set: 74811, number of used features: 28\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547286 -> initscore=0.189710\n","[LightGBM] [Info] Start training from score 0.189710\n","[LightGBM] [Info] Number of positive: 40944, number of negative: 33867\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013676 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1208\n","[LightGBM] [Info] Number of data points in the train set: 74811, number of used features: 28\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547299 -> initscore=0.189764\n","[LightGBM] [Info] Start training from score 0.189764\n","Stacking Classifier Validation Accuracy: 0.9675777407074725\n","Submission file saved successfully!\n"]}],"source":["from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n","from lightgbm import LGBMClassifier\n","from catboost import CatBoostClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Assuming 'train_df' is your training data and 'test_df' is your test data\n","X = train_df.drop(columns=['satisfaction'])  # Drop the target column from training data\n","y = train_df['satisfaction']  # Extract the target column\n","\n","# Split the training data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Identify categorical and numerical features\n","categorical_features = ['Gender', 'Customer Type', 'Type of Travel', 'Class']  # Add all your categorical columns here\n","numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n","\n","# Create transformers for numerical and categorical data\n","numeric_transformer = StandardScaler()\n","categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n","\n","# Combine transformers using ColumnTransformer\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numeric_transformer, numerical_features),\n","        ('cat', categorical_transformer, categorical_features)\n","    ])\n","\n","# Preprocess the data\n","X_train_scaled = preprocessor.fit_transform(X_train)\n","X_val_scaled = preprocessor.transform(X_val)\n","test_scaled = preprocessor.transform(test_df)  # Apply the same transformation to test data\n","\n","# Define base models\n","base_estimators = [\n","    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n","    ('catboost', CatBoostClassifier(verbose=0)),\n","    ('lightgbm', LGBMClassifier())\n","]\n","\n","# Define stacking classifier with logistic regression as the meta-model\n","stacking_clf = StackingClassifier(estimators=base_estimators, final_estimator=LogisticRegression(), cv=5)\n","\n","# Train the stacking model\n","stacking_clf.fit(X_train_scaled, y_train)\n","\n","# Predict on the validation set\n","y_val_pred_stacking = stacking_clf.predict(X_val_scaled)\n","stacking_accuracy = accuracy_score(y_val, y_val_pred_stacking)\n","print(f\"Stacking Classifier Validation Accuracy: {stacking_accuracy}\")\n","\n","# Predict on test data\n","test_predictions_stacking = stacking_clf.predict(test_scaled)\n","\n","# Prepare submission for Stacking\n","submission_stacking = pd.DataFrame({\n","    'ID': test_df['Id'],  # Assuming 'Id' is the identifier column in test_df\n","    'satisfaction': test_predictions_stacking\n","})\n","\n","# Correct the mapping: Ensure predictions are mapped to the expected labels\n","submission_stacking['satisfaction'] = submission_stacking['satisfaction'].map({1: 'satisfied', 0: 'dissatisfied'})\n","\n","# Save to CSV for Kaggle submission\n","submission_stacking.to_csv('submission_stacking.csv', index=False)\n","\n","print(\"Submission file saved successfully!\")"]},{"cell_type":"markdown","metadata":{"id":"S3k2FLkzYJvs"},"source":["##AdaBoost"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":64771,"status":"ok","timestamp":1728257006451,"user":{"displayName":"Athoye Mahmud (অথৈ)","userId":"05993942951772728166"},"user_tz":-360},"id":"k5OGtWE5YNW8","outputId":"06ee3426-867c-438a-ac2f-d7bd7b59d7e1"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["AdaBoost Validation Accuracy: 0.9275418110269901\n","AdaBoost submission file saved as 'submission_adaboost.csv'\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n","  warnings.warn(\n"]}],"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","\n","# Initialize AdaBoost with DecisionTree as base estimator (using 'estimator' instead of 'base_estimator')\n","ada_model = AdaBoostClassifier(\n","    estimator=DecisionTreeClassifier(max_depth=3),  # Fix: changed base_estimator to estimator\n","    n_estimators=100,\n","    learning_rate=0.1,\n","    random_state=42\n",")\n","\n","# Fit the model\n","ada_model.fit(X_train, y_train)\n","\n","# Evaluate on validation set\n","y_val_pred_ada = ada_model.predict(X_val)\n","ada_accuracy = accuracy_score(y_val, y_val_pred_ada)\n","print(f\"AdaBoost Validation Accuracy: {ada_accuracy}\")\n","\n","# Make predictions on the test set\n","test_predictions_ada = ada_model.predict(test_df_clean)\n","\n","# Prepare the submission DataFrame\n","submission_ada = pd.DataFrame({\n","    'Id': test_df['Id'],\n","    'satisfaction': test_predictions_ada\n","})\n","\n","# Convert numeric labels back to original text ('satisfied', 'dissatisfied')\n","submission_ada['satisfaction'] = submission_ada['satisfaction'].map({1: 'satisfied', 0: 'dissatisfied'})\n","\n","# Save submission to CSV\n","submission_ada.to_csv('submission_adaboost.csv', index=False)\n","print(\"AdaBoost submission file saved as 'submission_adaboost.csv'\")"]},{"cell_type":"markdown","metadata":{"id":"qo3uFFJTYTdr"},"source":["##CatBoost"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16169,"status":"ok","timestamp":1728166679294,"user":{"displayName":"Athoye Mahmud (অথৈ)","userId":"05993942951772728166"},"user_tz":-360},"id":"viMNOU3oYa0Y","outputId":"524891d5-bae7-4c41-bd84-97b01d368542"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.7)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n","Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (10.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.4)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n","CatBoost Validation Accuracy: 0.9613755934813294\n","CatBoost submission file saved as 'submission_catboost.csv'\n"]}],"source":["!pip install catboost\n","from catboost import CatBoostClassifier\n","\n","# Initialize CatBoost classifier\n","cat_model = CatBoostClassifier(iterations=500, learning_rate=0.1, depth=6, verbose=0, random_state=42)\n","\n","# Fit the model\n","cat_model.fit(X_train, y_train)\n","\n","# Evaluate on validation set\n","y_val_pred_cat = cat_model.predict(X_val)\n","cat_accuracy = accuracy_score(y_val, y_val_pred_cat)\n","print(f\"CatBoost Validation Accuracy: {cat_accuracy}\")\n","\n","# Make predictions on the test set\n","test_predictions_cat = cat_model.predict(test_df_clean)\n","\n","# Prepare the submission\n","submission_cat = pd.DataFrame({\n","    'ID': test_df['Id'],\n","    'satisfaction': test_predictions_cat\n","})\n","\n","submission_cat['satisfaction'] = submission_cat['satisfaction'].map({1: 'satisfied', 0: 'dissatisfied'})\n","submission_cat.to_csv('submission_catboost.csv', index=False)\n","print(\"CatBoost submission file saved as 'submission_catboost.csv'\")"]},{"cell_type":"markdown","metadata":{"id":"V4lwdDkJYec0"},"source":["##LightBGM"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14099,"status":"ok","timestamp":1728166708447,"user":{"displayName":"Athoye Mahmud (অথৈ)","userId":"05993942951772728166"},"user_tz":-360},"id":"7BqsLukyYioo","outputId":"45f19acf-5a95-4cdb-9ad5-76ef4b81569f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.5.0)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.13.1)\n","[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] Number of positive: 51176, number of negative: 42337\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009630 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 934\n","[LightGBM] [Info] Number of data points in the train set: 93513, number of used features: 22\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547261 -> initscore=0.189609\n","[LightGBM] [Info] Start training from score 0.189609\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","LightGBM Validation Accuracy: 0.9579109457205184\n","LightGBM submission file saved as 'submission_lightgbm.csv'\n"]}],"source":["!pip install lightgbm\n","import lightgbm as lgb\n","\n","# Initialize LightGBM model\n","lgb_model = lgb.LGBMClassifier(n_estimators=500, learning_rate=0.05, max_depth=6, random_state=42)\n","\n","# Fit the model\n","lgb_model.fit(X_train, y_train)\n","\n","# Evaluate on validation set\n","y_val_pred_lgb = lgb_model.predict(X_val)\n","lgb_accuracy = accuracy_score(y_val, y_val_pred_lgb)\n","print(f\"LightGBM Validation Accuracy: {lgb_accuracy}\")\n","\n","# Make predictions on the test set\n","test_predictions_lgb = lgb_model.predict(test_df_clean)\n","\n","# Prepare the submission\n","submission_lgb = pd.DataFrame({\n","    'ID': test_df['Id'],\n","    'satisfaction': test_predictions_lgb\n","})\n","\n","submission_lgb['satisfaction'] = submission_lgb['satisfaction'].map({1: 'satisfied', 0: 'dissatisfied'})\n","submission_lgb.to_csv('submission_lightgbm.csv', index=False)\n","print(\"LightGBM submission file saved as 'submission_lightgbm.csv'\")"]},{"cell_type":"markdown","metadata":{"id":"KY-rDKgMYlSj"},"source":["##K-Nearest Neighbors (KNN)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50806,"status":"ok","timestamp":1728166766275,"user":{"displayName":"Athoye Mahmud (অথৈ)","userId":"05993942951772728166"},"user_tz":-360},"id":"dnyNBPfaYtvz","outputId":"8c4a812d-7f36-4621-a93e-29b07b386936"},"outputs":[{"name":"stdout","output_type":"stream","text":["KNN Validation Accuracy: 0.9236066555455751\n","KNN submission file saved as 'submission_knn.csv'\n"]}],"source":["from sklearn.neighbors import KNeighborsClassifier\n","\n","# Initialize KNN (optimize for Colab by using smaller K)\n","knn_model = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n","\n","# Fit the model (scale data first)\n","knn_model.fit(X_train_scaled, y_train)\n","\n","# Evaluate on validation set\n","y_val_pred_knn = knn_model.predict(X_val_scaled)\n","knn_accuracy = accuracy_score(y_val, y_val_pred_knn)\n","print(f\"KNN Validation Accuracy: {knn_accuracy}\")\n","\n","# Make predictions on the test set (scaled test set)\n","test_scaled = scaler.transform(test_df_clean)\n","test_predictions_knn = knn_model.predict(test_scaled)\n","\n","# Prepare the submission\n","submission_knn = pd.DataFrame({\n","    'ID': test_df['Id'],\n","    'satisfaction': test_predictions_knn\n","})\n","\n","submission_knn['satisfaction'] = submission_knn['satisfaction'].map({1: 'satisfied', 0: 'dissatisfied'})\n","submission_knn.to_csv('submission_knn.csv', index=False)\n","print(\"KNN submission file saved as 'submission_knn.csv'\")"]},{"cell_type":"markdown","metadata":{"id":"lM1EGBzvU1p0"},"source":["##Neural Networks; Multilayer Perceptron(MLP) using Keras"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":85050,"status":"ok","timestamp":1728167054735,"user":{"displayName":"Athoye Mahmud (অথৈ)","userId":"05993942951772728166"},"user_tz":-360},"id":"5FfMqe7AVGnd","outputId":"cdf252dc-186d-415b-8e28-b1d93c37af52"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m2923/2923\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8819 - loss: 0.2732 - val_accuracy: 0.9302 - val_loss: 0.1691\n","Epoch 2/10\n","\u001b[1m2923/2923\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9342 - loss: 0.1570 - val_accuracy: 0.9383 - val_loss: 0.1462\n","Epoch 3/10\n","\u001b[1m2923/2923\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9405 - loss: 0.1388 - val_accuracy: 0.9439 - val_loss: 0.1331\n","Epoch 4/10\n","\u001b[1m2923/2923\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9472 - loss: 0.1250 - val_accuracy: 0.9435 - val_loss: 0.1281\n","Epoch 5/10\n","\u001b[1m2923/2923\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9475 - loss: 0.1200 - val_accuracy: 0.9494 - val_loss: 0.1234\n","Epoch 6/10\n","\u001b[1m2923/2923\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9507 - loss: 0.1146 - val_accuracy: 0.9509 - val_loss: 0.1172\n","Epoch 7/10\n","\u001b[1m2923/2923\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9525 - loss: 0.1094 - val_accuracy: 0.9491 - val_loss: 0.1161\n","Epoch 8/10\n","\u001b[1m2923/2923\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9535 - loss: 0.1069 - val_accuracy: 0.9519 - val_loss: 0.1135\n","Epoch 9/10\n","\u001b[1m2923/2923\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9551 - loss: 0.1034 - val_accuracy: 0.9501 - val_loss: 0.1134\n","Epoch 10/10\n","\u001b[1m2923/2923\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9563 - loss: 0.1004 - val_accuracy: 0.9531 - val_loss: 0.1111\n","Neural Network Validation Accuracy: 0.9530775547027588\n","\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n","Neural Network submission file saved as 'submission_nn.csv'\n"]}],"source":["from sklearn.preprocessing import StandardScaler, LabelEncoder\n","import pandas as pd\n","\n","# List of categorical columns (example: adjust based on your dataset)\n","categorical_cols = ['Gender', 'Customer Type', 'Type of Travel', 'Class']\n","\n","# Apply label encoding to categorical columns in both training and test data\n","label_encoders = {}\n","for col in categorical_cols:\n","    le = LabelEncoder()\n","    X_train[col] = le.fit_transform(X_train[col])\n","    test_df_clean[col] = le.transform(test_df_clean[col])\n","    label_encoders[col] = le\n","\n","# Scale the data (only after encoding)\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_val_scaled = scaler.transform(X_val)\n","test_scaled = scaler.transform(test_df_clean)  # Ensure the test set is scaled as well\n","\n","# Build the neural network (this part remains the same)\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","# Create Neural Network model\n","model = Sequential([\n","    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n","    Dense(32, activation='relu'),\n","    Dense(1, activation='sigmoid')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_data=(X_val_scaled, y_val))\n","\n","# Evaluate the model\n","nn_accuracy = model.evaluate(X_val_scaled, y_val, verbose=0)[1]\n","print(f\"Neural Network Validation Accuracy: {nn_accuracy}\")\n","\n","# Make predictions on the test set\n","test_predictions_nn = model.predict(test_scaled)\n","\n","# Convert probabilities to binary predictions\n","test_predictions_nn = (test_predictions_nn > 0.5).astype(int).flatten()\n","\n","# Prepare the submission DataFrame\n","submission_nn = pd.DataFrame({\n","    'Id': test_df['Id'],\n","    'satisfaction': test_predictions_nn\n","})\n","\n","# Convert numeric labels back to original text ('satisfied', 'dissatisfied')\n","submission_nn['satisfaction'] = submission_nn['satisfaction'].map({1: 'satisfied', 0: 'dissatisfied'})\n","\n","# Save submission to CSV\n","submission_nn.to_csv('submission_nn.csv', index=False)\n","print(\"Neural Network submission file saved as 'submission_nn.csv'\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":84274,"status":"ok","timestamp":1728167228032,"user":{"displayName":"Athoye Mahmud (অথৈ)","userId":"05993942951772728166"},"user_tz":-360},"id":"UiQZERb6yOrD","outputId":"42227571-3bc8-4d80-f4f4-805db75043a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m2923/2923\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8790 - loss: 0.2826 - val_accuracy: 0.9242 - val_loss: 0.1781\n","Epoch 2/10\n","\u001b[1m2923/2923\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9351 - loss: 0.1568 - val_accuracy: 0.9385 - val_loss: 0.1434\n","Epoch 3/10\n","\u001b[1m2923/2923\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9429 - loss: 0.1351 - val_accuracy: 0.9429 - val_loss: 0.1303\n","Epoch 4/10\n","\u001b[1m2923/2923\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9476 - loss: 0.1256 - val_accuracy: 0.9465 - val_loss: 0.1226\n","Epoch 5/10\n","\u001b[1m2923/2923\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9514 - loss: 0.1161 - val_accuracy: 0.9461 - val_loss: 0.1191\n","Epoch 6/10\n","\u001b[1m2923/2923\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9530 - loss: 0.1093 - val_accuracy: 0.9498 - val_loss: 0.1146\n","Epoch 7/10\n","\u001b[1m2923/2923\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9532 - loss: 0.1071 - val_accuracy: 0.9490 - val_loss: 0.1132\n","Epoch 8/10\n","\u001b[1m2923/2923\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9546 - loss: 0.1040 - val_accuracy: 0.9522 - val_loss: 0.1086\n","Epoch 9/10\n","\u001b[1m2923/2923\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9570 - loss: 0.0996 - val_accuracy: 0.9545 - val_loss: 0.1052\n","Epoch 10/10\n","\u001b[1m2923/2923\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9573 - loss: 0.0985 - val_accuracy: 0.9533 - val_loss: 0.1048\n","Neural Network Validation Accuracy: 0.9532914161682129\n","\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n","Neural Network submission file saved as 'submission_nn_keras.csv'\n"]}],"source":["from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","import pandas as pd\n","\n","# List of categorical columns (adjust based on your dataset)\n","categorical_cols = ['Gender', 'Customer Type', 'Type of Travel', 'Class']\n","\n","# Apply label encoding to categorical columns in both training and test data\n","label_encoders = {}\n","for col in categorical_cols:\n","    le = LabelEncoder()\n","    X_train[col] = le.fit_transform(X_train[col])\n","    test_df_clean[col] = le.transform(test_df_clean[col])\n","    label_encoders[col] = le\n","\n","# Scale the data after encoding\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_val_scaled = scaler.transform(X_val)\n","test_scaled = scaler.transform(test_df_clean)\n","\n","# Build the neural network using TensorFlow Keras\n","model = Sequential([\n","    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n","    Dense(32, activation='relu'),\n","    Dense(1, activation='sigmoid')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_data=(X_val_scaled, y_val))\n","\n","# Evaluate the model\n","nn_accuracy = model.evaluate(X_val_scaled, y_val, verbose=0)[1]\n","print(f\"Neural Network Validation Accuracy: {nn_accuracy}\")\n","\n","# Make predictions on the test set\n","test_predictions_nn = model.predict(test_scaled)\n","\n","# Convert probabilities to binary predictions (0 or 1)\n","test_predictions_nn = (test_predictions_nn > 0.5).astype(int).flatten()\n","\n","# Prepare the submission DataFrame\n","submission_nn = pd.DataFrame({\n","    'ID': test_df['Id'],\n","    'satisfaction': test_predictions_nn\n","})\n","\n","# Convert numeric labels back to original text ('satisfied', 'dissatisfied')\n","submission_nn['satisfaction'] = submission_nn['satisfaction'].map({1: 'satisfied', 0: 'dissatisfied'})\n","\n","# Save submission to CSV\n","submission_nn.to_csv('submission_nn.csv', index=False)\n","print(\"Neural Network submission file saved as 'submission_nn_keras.csv'\")"]},{"cell_type":"markdown","metadata":{"id":"1JIqWt8_lvWZ"},"source":["##**High-Performance Models**\n","*   Stacking with XGBoost, LightGBM, and RandomForest; A Logistic Regression Meta-model\n","*   Deep Neural Network (DNN); T4 GPU NEEDED!\n","*   XGBoost\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AbkG66UMl0Qf"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","import xgboost as xgb\n","import lightgbm as lgb\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","\n","# Step 3: Preprocessing\n","# Handling categorical columns (e.g., encoding)\n","train_df['Gender'] = train_df['Gender'].map({'Male': 1, 'Female': 0})\n","\n","# Define feature and target variables\n","X = train_df.drop(['Id', 'satisfaction'], axis=1)\n","y = train_df['satisfaction'].map({'satisfied': 1, 'dissatisfied': 0})\n","\n","# Train-test split\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Define the categorical columns\n","categorical_cols = ['Customer Type', 'Type of Travel', 'Class']\n","\n","# Handle categorical features before scaling\n","for col in categorical_cols:\n","    le = LabelEncoder()\n","    X_train[col] = le.fit_transform(X_train[col])\n","    X_val[col] = le.transform(X_val[col])\n","\n","# Standard scaling\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_val_scaled = scaler.transform(X_val)\n","\n","# Step 4: Base Models\n","xgb_model = xgb.XGBClassifier(\n","    n_estimators=500,\n","    max_depth=7,\n","    learning_rate=0.01)\n","lgb_model = lgb.LGBMClassifier(\n","    n_estimators=500,\n","    max_depth=7,\n","    learning_rate=0.01)\n","rf_model = RandomForestClassifier(\n","    n_estimators=100)\n","\n","# Step 5: Stacking Classifier\n","estimators = [\n","    ('xgb', xgb_model),\n","    ('lgb', lgb_model),\n","    ('rf', rf_model)\n","]\n","\n","stacking_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n","\n","# Train the stacking model\n","stacking_model.fit(X_train_scaled, y_train)\n","\n","# Evaluate on validation set\n","y_val_pred_stack = stacking_model.predict(X_val_scaled)\n","print(f\"Stacking Model Validation Accuracy: {accuracy_score(y_val, y_val_pred_stack)}\")\n","\n","# Step 6: Build DNN Model\n","def build_dnn(input_shape):\n","    model = Sequential()\n","    model.add(Dense(512, activation='relu', input_shape=(input_shape,)))\n","    model.add(Dropout(0.3))\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dropout(0.3))\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dropout(0.3))\n","    model.add(Dense(1, activation='sigmoid'))  # Binary classification\n","    return model\n","\n","# Compile the model\n","dnn_model = build_dnn(input_shape=X_train_scaled.shape[1])\n","dnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Step 7: Train the DNN Model\n","dnn_model.fit(X_train_scaled, y_train, epochs=20, batch_size=128, validation_data=(X_val_scaled, y_val))\n","\n","# Evaluate the DNN model on validation set\n","dnn_val_pred = (dnn_model.predict(X_val_scaled) > 0.5).astype(\"int32\")\n","print(f\"DNN Validation Accuracy: {accuracy_score(y_val, dnn_val_pred)}\")\n","\n","# Step 8: Train XGBoost with GPU Support\n","xgb_gpu_model = xgb.XGBClassifier(\n","    n_estimators=500,\n","    max_depth=7,\n","    learning_rate=0.01\n",")\n","xgb_gpu_model.fit(X_train_scaled, y_train)\n","\n","# Evaluate the XGBoost model\n","xgb_val_pred = xgb_gpu_model.predict(X_val_scaled)\n","print(f\"XGBoost Validation Accuracy: {accuracy_score(y_val, xgb_val_pred)}\")\n","\n","# Step 9: Prepare test data\n","X_test = test_df.drop(['Id'], axis=1)\n","X_test['Gender'] = X_test['Gender'].map({'Male': 1, 'Female': 0})  # Adjust encoding if necessary\n","\n","# Apply label encoding to categorical columns in the test data\n","for col in categorical_cols:\n","    le = LabelEncoder()\n","    X_test[col] = le.fit_transform(X_test[col]) # Encode categorical features in test data\n","\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Step 10: Predictions for Submission\n","stacking_test_pred = stacking_model.predict(X_test_scaled)\n","dnn_test_pred = (dnn_model.predict(X_test_scaled) > 0.5).astype(\"int32\")\n","xgb_test_pred = xgb_gpu_model.predict(X_test_scaled)\n","\n","# Step 11: Create Submission Files\n","submission_stacking = pd.DataFrame({'ID': test_df['Id'], 'satisfaction': stacking_test_pred})\n","submission_dnn = pd.DataFrame({'ID': test_df['Id'], 'satisfaction': dnn_test_pred.flatten()})\n","submission_xgb = pd.DataFrame({'ID': test_df['Id'], 'satisfaction': xgb_test_pred})\n","\n","# Save the submissions as CSV files\n","submission_stacking.to_csv(\"submission_stacking.csv\", index=False)\n","submission_dnn.to_csv(\"submission_dnn.csv\", index=False)\n","submission_xgb.to_csv(\"submission_xgb.csv\", index=False)\n","\n","print(\"Submissions saved successfully!\")"]},{"cell_type":"markdown","metadata":{"id":"OqD9YDLCFNT9"},"source":["##GridSearchCV"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uFWn9NJ7FYLc","outputId":"932a9e6c-af7a-4264-8283-dbe23c885bcb"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["['Id', 'satisfaction', 'Gender', 'Customer Type', 'Age', 'Type of Travel', 'Class', 'Flight Distance', 'Seat comfort', 'Departure/Arrival time convenient', 'Food and drink', 'Gate location', 'Inflight wifi service', 'Inflight entertainment', 'Online support', 'Ease of Online booking', 'On-board service', 'Leg room service', 'Baggage handling', 'Checkin service', 'Cleanliness', 'Online boarding', 'Departure Delay in Minutes', 'Arrival Delay in Minutes']\n","Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"]}],"source":["from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","import pandas as pd\n","import numpy as np\n","\n","print(train_df.columns.tolist())\n","\n","# Data Cleaning\n","train_df_clean = train_df.drop(columns=['Id'])\n","test_df_clean = test_df.drop(columns=['Id'])\n","\n","# Impute missing values\n","imputer = SimpleImputer(strategy='median')\n","train_df_clean['Arrival Delay in Minutes'] = imputer.fit_transform(train_df_clean[['Arrival Delay in Minutes']])\n","test_df_clean['Arrival Delay in Minutes'] = imputer.transform(test_df_clean[['Arrival Delay in Minutes']])\n","\n","# Label Encoding for binary columns\n","train_df_clean['satisfaction'] = train_df_clean['satisfaction'].map({'satisfied': 1, 'dissatisfied': 0})\n","\n","# Ordinal Encoding for ratings columns (e.g., Seat comfort, Online support)\n","ratings_cols = ['Seat comfort', 'Departure/Arrival time convenient', 'Food and drink',\n","                'Gate location', 'Inflight wifi service', 'Inflight entertainment',\n","                'Online support', 'Ease of Online booking', 'On-board service',\n","                'Leg room service', 'Baggage handling', 'Checkin service',\n","                'Cleanliness', 'Online boarding']\n","ordinal_encoder = OrdinalEncoder()\n","train_df_clean[ratings_cols] = ordinal_encoder.fit_transform(train_df_clean[ratings_cols])\n","test_df_clean[ratings_cols] = ordinal_encoder.transform(test_df_clean[ratings_cols])\n","\n","# One-Hot Encoding for nominal categorical columns\n","categorical_cols = ['Gender', 'Customer Type', 'Type of Travel', 'Class']\n","one_hot_encoder = OneHotEncoder(handle_unknown='ignore', drop='first') # remove sparse argument, add handle_unknown to avoid errors\n","encoded_train = one_hot_encoder.fit_transform(train_df_clean[categorical_cols])\n","encoded_test = one_hot_encoder.transform(test_df_clean[categorical_cols])\n","\n","# Append encoded columns\n","train_df_clean = train_df_clean.join(pd.DataFrame.sparse.from_spmatrix(encoded_train, columns=one_hot_encoder.get_feature_names_out(categorical_cols))) # Use sparse.from_spmatrix to convert the sparse matrix to a DataFrame\n","test_df_clean = test_df_clean.join(pd.DataFrame.sparse.from_spmatrix(encoded_test, columns=one_hot_encoder.get_feature_names_out(categorical_cols))) # Use sparse.from_spmatrix to convert the sparse matrix to a DataFrame\n","\n","# Drop the original categorical columns\n","train_df_clean = train_df_clean.drop(columns=categorical_cols)\n","test_df_clean = test_df_clean.drop(columns=categorical_cols)\n","\n","# Define features and target\n","X = train_df_clean.drop(columns=['satisfaction'])\n","y = train_df_clean['satisfaction']\n","\n","# Split data\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","\n","# Random Forest Classifier with hyperparameter tuning\n","rf_model = RandomForestClassifier(random_state=42)\n","\n","param_grid = {\n","    'n_estimators': [100, 200, 300],\n","    'max_depth': [10, 20, 30],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4],\n","    'bootstrap': [True, False]\n","}\n","\n","# Grid search with cross-validation\n","cv = StratifiedKFold(n_splits=5)\n","grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=cv, n_jobs=-1, verbose=2)\n","grid_search.fit(X_train, y_train)\n","\n","# Best hyperparameters\n","print(grid_search.best_params_)\n","\n","# Make predictions on validation set\n","y_val_pred = grid_search.predict(X_val)\n","val_accuracy = accuracy_score(y_val, y_val_pred)\n","print(f\"Validation Accuracy: {val_accuracy}\")\n","\n","# Predictions for test set and submission\n","test_predictions = grid_search.predict(test_df_clean)\n","submission_df = pd.DataFrame({\n","    'ID': test_df['Id'],\n","    'satisfaction': test_predictions\n","})\n","submission_df['satisfaction'] = submission_df['satisfaction'].map({1: 'satisfied', 0: 'dissatisfied'})\n","submission_df.to_csv('submission.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"LaS5IAlsKlO5"},"source":["##RandomizedSearchCV"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"CaHTUVrdKomH","outputId":"6128941f-d57a-4b87-f2e4-cea02ac48958"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n","  _data = np.array(data, dtype=dtype, copy=copy,\n"]},{"name":"stdout","output_type":"stream","text":["Best hyperparameters found by RandomizedSearchCV:\n","{'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 30, 'bootstrap': False}\n","Validation Accuracy: 0.9581675862953933\n","\n","Classification Report on Validation Set:\n","              precision    recall  f1-score   support\n","\n","           0       0.94      0.97      0.95     10585\n","           1       0.97      0.95      0.96     12794\n","\n","    accuracy                           0.96     23379\n","   macro avg       0.96      0.96      0.96     23379\n","weighted avg       0.96      0.96      0.96     23379\n","\n","Submission file saved to: /content/drive/MyDrive/Code/DS_1101/Fly High With FDS/Black-Mesa-Survivors_08_RandomizedSearchCV.csv\n"]}],"source":["# Import required libraries\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.impute import SimpleImputer\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.model_selection import StratifiedKFold\n","\n","# Data Preprocessing\n","# Dropping the 'Id' column (not useful for modeling) from both train and test datasets\n","train_df_clean = train_df.drop(columns=['Id'])\n","test_df_clean = test_df.drop(columns=['Id'])\n","\n","# Handle missing values (Impute 'Arrival Delay in Minutes' with the median)\n","imputer = SimpleImputer(strategy='median')\n","train_df_clean['Arrival Delay in Minutes'] = imputer.fit_transform(train_df_clean[['Arrival Delay in Minutes']])\n","test_df_clean['Arrival Delay in Minutes'] = imputer.transform(test_df_clean[['Arrival Delay in Minutes']])\n","\n","# Encode categorical variables using LabelEncoder\n","categorical_cols = ['Gender', 'Customer Type', 'Type of Travel', 'Class']\n","\n","label_encoders = {}\n","for col in categorical_cols:\n","    le = LabelEncoder()\n","    # Fit the LabelEncoder on the combined unique values from both train and test data\n","    le.fit(pd.concat([train_df_clean[col], test_df_clean[col]], axis=0).unique())\n","    train_df_clean[col] = le.transform(train_df_clean[col])\n","    test_df_clean[col] = le.transform(test_df_clean[col])\n","    label_encoders[col] = le\n","\n","# Encode the target variable 'satisfaction'\n","train_df_clean['satisfaction'] = train_df_clean['satisfaction'].map({'satisfied': 1, 'dissatisfied': 0})\n","\n","# Separate features and target variable\n","X = train_df_clean.drop(columns=['satisfaction'])\n","y = train_df_clean['satisfaction']\n","\n","# Split the data into training and validation sets (80-20 split)\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","\n","# Define the Random Forest Classifier model\n","rf_model = RandomForestClassifier(random_state=42)\n","\n","# Define the hyperparameter grid for RandomizedSearchCV\n","param_distributions = {\n","    'n_estimators': [100, 200, 300],\n","    'max_depth': [10, 20, 30],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4],\n","    'bootstrap': [True, False]\n","}\n","\n","# Initialize RandomizedSearchCV with 3-fold cross-validation\n","random_search = RandomizedSearchCV(\n","    estimator=rf_model,\n","    param_distributions=param_distributions,\n","    n_iter=50,  # Try 50 random combinations of hyperparameters\n","    cv=3,       # 3-fold cross-validation\n","    n_jobs=-1,  # Use all CPU cores\n","    verbose=2,\n","    random_state=42\n",")\n","\n","# Fit the model on training data\n","random_search.fit(X_train, y_train)\n","\n","# Get the best hyperparameters\n","print(\"Best hyperparameters found by RandomizedSearchCV:\")\n","print(random_search.best_params_)\n","\n","# Evaluate on the validation set\n","y_val_pred = random_search.predict(X_val)\n","val_accuracy = accuracy_score(y_val, y_val_pred)\n","print(f\"Validation Accuracy: {val_accuracy}\")\n","print(\"\\nClassification Report on Validation Set:\")\n","print(classification_report(y_val, y_val_pred))\n","\n","# Make predictions on the test set\n","test_predictions = random_search.predict(test_df_clean)\n","\n","# Prepare the submission file\n","submission_df = pd.DataFrame({\n","    'ID': test_df['Id'],  # Re-include 'Id' from the original test dataset\n","    'satisfaction': test_predictions\n","})\n","\n","# Convert 'satisfaction' back to original labels ('satisfied' or 'dissatisfied')\n","submission_df['satisfaction'] = submission_df['satisfaction'].map({1: 'satisfied', 0: 'dissatisfied'})\n","\n","# Save the submission file\n","submission_file_path = '/content/drive/MyDrive/Code/DS_1101/Fly High With FDS/Black-Mesa-Survivors_08_RandomizedSearchCV.csv'\n","submission_df.to_csv(submission_file_path, index=False)\n","\n","print(f\"Submission file saved to: {submission_file_path}\")"]},{"cell_type":"markdown","source":["##Full Random Forest Implementation with Extended Preprocessing and Feature Engineering\n"],"metadata":{"id":"pWfHsaaPOUpx"}},{"cell_type":"code","source":["# Import required libraries\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold, cross_val_score\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.feature_selection import SelectFromModel\n","\n","# EDA and Data Visualization\n","def plot_feature_distribution(df, feature, title):\n","    plt.figure(figsize=(8, 6))\n","    sns.countplot(x=feature, data=df)\n","    plt.title(title)\n","    plt.xticks(rotation=45)\n","    plt.show()\n","\n","# Data Preprocessing\n","def preprocess_data(train_df, test_df):\n","    # Drop 'Id' column as it is not useful for modeling\n","    train_df_clean = train_df.drop(columns=['Id'])\n","    test_df_clean = test_df.drop(columns=['Id'])\n","\n","    # Handle missing values (Impute 'Arrival Delay in Minutes' with the median)\n","    imputer = SimpleImputer(strategy='median')\n","    train_df_clean['Arrival Delay in Minutes'] = imputer.fit_transform(train_df_clean[['Arrival Delay in Minutes']])\n","    test_df_clean['Arrival Delay in Minutes'] = imputer.transform(test_df_clean[['Arrival Delay in Minutes']])\n","\n","    # Feature Engineering: Add new features like total flights or flight categories if possible (domain-specific knowledge)\n","    # Example: Binning 'Flight Distance' into categories (short, medium, long flights)\n","    train_df_clean['Flight Distance Category'] = pd.cut(train_df_clean['Flight Distance'],\n","                                                       bins=[0, 1000, 3000, np.inf],\n","                                                       labels=['short', 'medium', 'long'])\n","    test_df_clean['Flight Distance Category'] = pd.cut(test_df_clean['Flight Distance'],\n","                                                      bins=[0, 1000, 3000, np.inf],\n","                                                      labels=['short', 'medium', 'long'])\n","\n","    # Encode categorical variables using LabelEncoder\n","    categorical_cols = ['Gender', 'Customer Type', 'Type of Travel', 'Class', 'Flight Distance Category']\n","\n","    label_encoders = {}\n","    for col in categorical_cols:\n","        le = LabelEncoder()\n","        le.fit(pd.concat([train_df_clean[col], test_df_clean[col]], axis=0).unique())\n","        train_df_clean[col] = le.transform(train_df_clean[col])\n","        test_df_clean[col] = le.transform(test_df_clean[col])\n","        label_encoders[col] = le\n","\n","    # Encode the target variable 'satisfaction'\n","    train_df_clean['satisfaction'] = train_df_clean['satisfaction'].map({'satisfied': 1, 'dissatisfied': 0})\n","\n","    # Standardize features like 'Flight Distance', 'Departure Delay' and 'Arrival Delay'\n","    scaler = StandardScaler()\n","    numerical_cols = ['Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes']\n","    train_df_clean[numerical_cols] = scaler.fit_transform(train_df_clean[numerical_cols])\n","    test_df_clean[numerical_cols] = scaler.transform(test_df_clean[numerical_cols])\n","\n","    return train_df_clean, test_df_clean\n","\n","# Random Forest with Hyperparameter Tuning and Cross-Validation\n","def random_forest_model(X, y, X_test, test_df, output_path):\n","    # Split the data into training and validation sets (80-20 split)\n","    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","\n","    # Define Random Forest model\n","    rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n","\n","    # Hyperparameter tuning grid\n","    param_distributions = {\n","        'n_estimators': [100, 200, 300, 400],\n","        'max_depth': [10, 20, 30, 40],\n","        'min_samples_split': [2, 5, 10],\n","        'min_samples_leaf': [1, 2, 4],\n","        'bootstrap': [True, False],\n","        'max_features': ['auto', 'sqrt', 'log2']\n","    }\n","\n","    # Stratified K-Folds Cross-Validation\n","    skf = StratifiedKFold(n_splits=5)\n","\n","    # Randomized Search CV for hyperparameter tuning\n","    random_search = RandomizedSearchCV(\n","        estimator=rf_model,\n","        param_distributions=param_distributions,\n","        n_iter=50,\n","        cv=skf,\n","        scoring='accuracy',\n","        n_jobs=-1,\n","        verbose=2,\n","        random_state=42\n","    )\n","\n","    # Fit the RandomizedSearchCV model\n","    random_search.fit(X_train, y_train)\n","\n","    # Best hyperparameters\n","    print(\"Best hyperparameters found by RandomizedSearchCV:\")\n","    print(random_search.best_params_)\n","\n","    # Evaluate on the validation set\n","    y_val_pred = random_search.predict(X_val)\n","    val_accuracy = accuracy_score(y_val, y_val_pred)\n","    print(f\"Validation Accuracy: {val_accuracy}\")\n","    print(\"\\nClassification Report on Validation Set:\")\n","    print(classification_report(y_val, y_val_pred))\n","\n","    # Confusion Matrix for better insight\n","    cm = confusion_matrix(y_val, y_val_pred)\n","    sns.heatmap(cm, annot=True, fmt='d')\n","    plt.title('Confusion Matrix on Validation Set')\n","    plt.show()\n","\n","    # Feature Importance for potential feature selection\n","    importances = random_search.best_estimator_.feature_importances_\n","    indices = np.argsort(importances)[::-1]\n","    plt.figure(figsize=(12, 8))\n","    plt.title('Feature Importance')\n","    plt.bar(range(X_train.shape[1]), importances[indices], align='center')\n","    plt.xticks(range(X_train.shape[1]), X_train.columns[indices], rotation=90)\n","    plt.tight_layout()\n","    plt.show()\n","\n","    # Select top features using SelectFromModel\n","    selector = SelectFromModel(random_search.best_estimator_, threshold=\"median\")\n","    X_train_selected = selector.fit_transform(X_train, y_train)\n","    X_test_selected = selector.transform(X_test)\n","\n","    # Refit model on selected features\n","    random_search.best_estimator_.fit(X_train_selected, y_train)\n","\n","    # Make predictions on the test set with selected features\n","    test_predictions = random_search.best_estimator_.predict(X_test_selected)\n","\n","    # Prepare the submission DataFrame\n","    submission_df = pd.DataFrame({\n","        'ID': test_df['Id'],  # Re-include 'Id' from the original test dataset\n","        'satisfaction': test_predictions\n","    })\n","\n","    # Convert 'satisfaction' back to original labels ('satisfied' or 'dissatisfied')\n","    submission_df['satisfaction'] = submission_df['satisfaction'].map({1: 'satisfied', 0: 'dissatisfied'})\n","\n","    # Save the submission file\n","    submission_df.to_csv(output_path, index=False)\n","    print(f\"Submission file saved to: {output_path}\")\n","\n","# Load data\n","train_df = pd.read_csv('/content/drive/MyDrive/Code/DS_1101/Fly High With FDS/train.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/Code/DS_1101/Fly High With FDS/train.csv')\n","\n","# Preprocess the data\n","train_df_clean, test_df_clean = preprocess_data(train_df, test_df)\n","\n","# Separate features and target\n","X = train_df_clean.drop(columns=['satisfaction'])\n","y = train_df_clean['satisfaction']\n","\n","# Run Random Forest Model\n","output_path = '/content/drive/MyDrive/Code/DS_1101/Fly High With FDS/Black-Mesa-Survivors_11_RandomForest_Extra.csv'\n","random_forest_model(X, y, test_df_clean, test_df, output_path)"],"metadata":{"id":"AiEfHIG7OW9F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Stratified K-Fold Cross-Validation"],"metadata":{"id":"ZuqKtff68CdR"}},{"cell_type":"code","source":["!pip install category_encoders\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from category_encoders import TargetEncoder\n","import warnings # Importing warnings library to ignore the warning in future.\n","warnings.filterwarnings(\"ignore\") # Code to ignore warnings in future.\n","\n","# Preprocessing function (same as before)\n","def preprocess_data(train_df, test_df):\n","    # Separate features and target variable\n","    X = train_df.drop(['satisfaction', 'Id'], axis=1)\n","    y = train_df['satisfaction'].map({'satisfied': 1, 'neutral or dissatisfied': 0})\n","    X_test = test_df.drop('Id', axis=1)\n","\n","    # Identify numerical and categorical features\n","    numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n","    categorical_features = X.select_dtypes(include=['object']).columns\n","\n","    # Create transformers for numerical and categorical features\n","    numerical_transformer = Pipeline(steps=[\n","        ('imputer', SimpleImputer(strategy='median')),\n","        ('scaler', StandardScaler())\n","    ])\n","\n","    categorical_transformer = Pipeline(steps=[\n","        ('imputer', SimpleImputer(strategy='most_frequent')),\n","        ('target_encoder', TargetEncoder())  # Using TargetEncoder\n","    ])\n","\n","    # Combine transformers using ColumnTransformer\n","    preprocessor = ColumnTransformer(\n","        transformers=[\n","            ('num', numerical_transformer, numerical_features),\n","            ('cat', categorical_transformer, categorical_features)\n","        ])\n","\n","    # Handle missing values in the target variable (y) before fitting\n","    y = y.fillna(y.mode()[0]) # Fill missing values with the mode\n","\n","    # Fit and transform the training data\n","    X = preprocessor.fit_transform(X, y)\n","\n","    # Transform the test data\n","    X_test = preprocessor.transform(X_test)\n","\n","    return X, X_test, y\n","\n","\n","# Load and preprocess\n","train_df = pd.read_csv('train.csv')\n","test_df = pd.read_csv('test.csv')\n","X, X_test, y = preprocess_data(train_df, test_df)\n","\n","# Stratified K-Fold Cross-Validation\n","n_splits = 5  # Number of folds (adjust as needed)\n","skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n","\n","# Store results for each fold\n","cv_scores = []\n","cv_classification_reports = []\n","test_predictions = [] # Initialize test predictions with size equal to no. of folds.\n","\n","for fold, (train_index, val_index) in enumerate(skf.split(X, y)):\n","    X_train, X_val = X[train_index], X[val_index]\n","    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n","\n","    # Hyperparameter Tuning with RandomizedSearchCV inside each fold\n","    param_dist = {\n","    'n_estimators': [100, 200, 300, 500],  # Explore a range\n","    'max_depth': [None, 10, 20, 30],         # Include None for full depth\n","    'min_samples_split': [2, 5, 10],        # Experiment with splitting criteria\n","    'min_samples_leaf': [1, 2, 4],          # Control leaf size\n","    'max_features': ['sqrt', 'log2', None], # Or a float between 0 and 1\n","    'bootstrap': [True, False],            # Bagging (with replacement) or Pasting\n","    'class_weight': [None, 'balanced', 'balanced_subsample']} # Adjust for class imbalance (if any)\n","# Hyperparameter grid for Random Forest\n","\n","    rf = RandomForestClassifier(random_state=42)\n","    random_search = RandomizedSearchCV(\n","        rf, param_distributions=param_dist, n_iter=50,  # Increase n_iter for wider search\n","        scoring='accuracy', cv=5, n_jobs=-1, verbose=2, random_state=42\n","    )  # Inner cross-validation within each fold\n","\n","    random_search.fit(X_train, y_train)\n","\n","    best_rf = random_search.best_estimator_\n","\n","\n","    # Evaluate on validation fold\n","    y_pred = best_rf.predict(X_val)\n","    accuracy = accuracy_score(y_val, y_pred)\n","    classification_rep = classification_report(y_val, y_pred)\n","    cv_scores.append(accuracy)\n","    cv_classification_reports.append(classification_rep)\n","    test_predictions.append(best_rf.predict_proba(X_test))\n","\n","    print(f\"Fold {fold+1} Accuracy: {accuracy}\")\n","    print(f\"Fold {fold+1} Classification Report:\\n{classification_rep}\\n\")\n","\n","# Summarize CV performance\n","print(\"Average cross-validation accuracy:\", np.mean(cv_scores))\n","print(\"Standard deviation of cross-validation accuracy:\", np.std(cv_scores))\n","\n","\n","# Create a submission based on the average of multiple models.\n","averaged_predictions = np.mean(test_predictions, axis = 0)\n","submission_df = pd.DataFrame({\n","    'ID': test_df['Id'],\n","    'satisfaction': (averaged_predictions[:, 1] > 0.5).astype(int)\n","})\n","\n","submission_df['satisfaction'] = submission_df['satisfaction'].map({1: 'satisfied', 0: 'dissatisfied'})\n","\n","submission_df.to_csv(\"averaged_model_submission.csv\", index=False)"],"metadata":{"id":"-YQtbvgO7QHR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dc00f131-dab4-4e48-ac0e-6c365a5415ef"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Requirement already satisfied: category_encoders in /usr/local/lib/python3.10/dist-packages (2.6.4)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.26.4)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.5.2)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.13.1)\n","Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.14.3)\n","Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (2.2.2)\n","Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.5.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2024.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.5.0)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.9.0->category_encoders) (24.1)\n","Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"]}]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1DayrqpdawEl2ta0S3uAcSWclJ5ESPd48","authorship_tag":"ABX9TyMUcRKG7XVeMY+Ptf6vYCof"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}